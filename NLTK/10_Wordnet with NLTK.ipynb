{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a90a760-ba2f-40c0-9561-b76db22619dc",
   "metadata": {},
   "source": [
    "## Wordnet with NLTK\n",
    "\n",
    "WordNet is a lexical database for the English language, which was created by Princeton, and is part of the NLTK corpus.\n",
    "\n",
    "We can use WordNet alongside the NLTK module to find the meanings of words, synonyms, antonyms, and more. \n",
    "\n",
    "Let's cover some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1b072d-288c-4c5e-8826-4a8e7d02dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b93727-24b2-406f-a654-c1a3a5743ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the term \"program\" to find synsets like\n",
    "syns = wordnet.synsets(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f4d0a3-f4bc-49f9-b74c-a08cbf8dbd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plan.n.01'),\n",
       " Synset('program.n.02'),\n",
       " Synset('broadcast.n.02'),\n",
       " Synset('platform.n.02'),\n",
       " Synset('program.n.05'),\n",
       " Synset('course_of_study.n.01'),\n",
       " Synset('program.n.07'),\n",
       " Synset('program.n.08'),\n",
       " Synset('program.v.01'),\n",
       " Synset('program.v.02')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e075942-0671-4507-88de-5e68578d4b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan.n.01\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7a3192-e631-4bfa-b93e-389874051a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('plan.n.01.plan')\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].lemmas()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a585b73-95d9-4773-a76c-19b446a25fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plan\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3fb35ad-a777-43aa-a553-41dfccca7b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program\n"
     ]
    }
   ],
   "source": [
    "print(syns[1].lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33d2c73-2dfe-4f0e-9e8b-4d878f21cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].lemmas()[1].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9137b975-89f1-46ea-ab01-f25917204aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a series of steps to be carried out or goals to be accomplished\n"
     ]
    }
   ],
   "source": [
    "# Definition of that first synset:\n",
    "\n",
    "print(syns[0].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "319f198f-3be6-4173-8bae-ec446570c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
     ]
    }
   ],
   "source": [
    "print(syns[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bcea7-2835-41b8-b815-bd076ee42900",
   "metadata": {},
   "source": [
    "### synonyms and antonyms to a word? The lemmas will be synonyms, and then you can use .antonyms to find the antonyms to the lemmas. As such, we can populate some lists like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8078fd3-411c-4e91-9839-da28e752556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'full', 'trade_good', 'honorable', 'well', 'honest', 'unspoilt', 'in_effect', 'ripe', 'unspoiled', 'commodity', 'safe', 'undecomposed', 'respectable', 'skilful', 'expert', 'near', 'goodness', 'serious', 'dear', 'effective', 'secure', 'beneficial', 'estimable', 'just', 'adept', 'practiced', 'salutary', 'dependable', 'soundly', 'good', 'in_force', 'thoroughly', 'upright', 'skillful', 'proficient', 'sound', 'right'} \n",
      "\n",
      "{'evilness', 'ill', 'evil', 'bad', 'badness'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms), '\\n')\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a816fb73-fea5-49ae-bf68-3223b540552f",
   "metadata": {},
   "source": [
    "### we can also easily use WordNet to compare the similarity of two words and their tenses, by incorporating the **Wu and Palmer** method for semantic related-ness.\n",
    "\n",
    "Let's compare the noun of \"ship\" and \"boat:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b64fabdd-df5b-4370-9390-fad0d57188ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('boat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1847de7a-cd8c-476f-b889-93846ff0acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('car.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f1071cd-46c0-4423-b457-1a2f4d0870f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "w1 = wordnet.synset('ship.n.01')\n",
    "w2 = wordnet.synset('cat.n.01')\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eabe21-f4fb-4da9-9e38-5032fddcb8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pytorch_p39",
   "language": "python",
   "name": "dl_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
