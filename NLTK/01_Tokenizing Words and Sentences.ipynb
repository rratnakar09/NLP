{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5fc54c-73a6-497c-a771-7f98d056e571",
   "metadata": {},
   "source": [
    "## Tokenizing Words and Sentences with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da516830-1f7b-4b47-9b99-190954f64a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de46bca-0270-43c7-bbb6-250d2a67d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb402b-c066-4b63-ab77-0219d8fc3012",
   "metadata": {},
   "source": [
    "__Corpus__ - Body of text, singular. Corpora is the plural of this. Example: A collection of medical journals.\n",
    "\n",
    "__Lexicon__ - Words and their meanings. \n",
    "Example: English dictionary. Consider, however, that various fields will have different lexicons. For example: To a financial investor, the first meaning for the word \"Bull\" is someone who is confident about the market, as compared to the common English lexicon, where the first meaning for the word \"Bull\" is an animal. As such, there is a special lexicon for financial investors, doctors, children, mechanics, and so on.\n",
    "\n",
    "__Token__ - Each \"entity\" that is a part of whatever was split up based on rules. For examples, each word is a token when a sentence is \"tokenized\" into words. Each sentence can also be a token, if you tokenized the sentences out of a paragraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90bc2af-6a9b-4e12-864a-636cf555a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\"]\n"
     ]
    }
   ],
   "source": [
    "# let's see an example of how we can tokenize something into tokens with the NLTK module.\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(sent_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fb1f007-409e-40db-85ac-b685cda500eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mr. Smith, how are you doing today?\n",
      "The weather is great, and Python is awesome.\n",
      "The sky is pinkish-blue.\n",
      "You shouldn't eat cardboard.\n"
     ]
    }
   ],
   "source": [
    "for sen in sent_tokenize(EXAMPLE_TEXT):\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a0b6d4f-829f-472d-976d-49d1f27948d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India is a secular country.', 'The capital of India is New Delhi.', 'The Tajmahal is the seventh wonder of the world.']\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_TEXT = \"India is a secular country. The capital of India is New Delhi. The Tajmahal is the seventh wonder of the world.\"\n",
    "print(sent_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4a95b78-ecb3-4184-a21d-5cb5688765b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is a secular country.\n",
      "The capital of India is New Delhi.\n",
      "The Tajmahal is the seventh wonder of the world.\n"
     ]
    }
   ],
   "source": [
    "for sen in sent_tokenize(EXAMPLE_TEXT):\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dce315a-ddc0-4a8f-9687-52b9063c214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
     ]
    }
   ],
   "source": [
    "# Let's tokenize by word\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\"\n",
    "\n",
    "print(word_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b595e1cc-98d6-49c9-a3ed-d61db6e98ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India is a secular country.', 'The capital of India is New Delhi.', 'The Tajmahal is the seventh wonder of the world.'] \n",
      "\n",
      "Word Tokenized\n",
      "['India', 'is', 'a', 'secular', 'country', '.', 'The', 'capital', 'of', 'India', 'is', 'New', 'Delhi', '.', 'The', 'Tajmahal', 'is', 'the', 'seventh', 'wonder', 'of', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_TEXT = \"India is a secular country. The capital of India is New Delhi. The Tajmahal is the seventh wonder of the world.\"\n",
    "print(sent_tokenize(EXAMPLE_TEXT), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Word Tokenized\")\n",
    "\n",
    "print(word_tokenize(EXAMPLE_TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9ba38-9eed-46a7-94d9-79d4ca89f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pytorch_p39",
   "language": "python",
   "name": "dl_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
